# Quantum Mamba Models - Comprehensive Documentation

> Quantum implementations of the Mamba architecture for ablation studies

## ğŸ¯ Overview

This document describes **two quantum implementations of the Mamba architecture** (Gu & Dao, 2024) designed for ablation studies comparing quantum and classical state-space models.

### Why Quantum Mamba?

1. **Ablation Study**: Compare Quantum Hydra vs Quantum Mamba to determine if quantum advantages are architecture-specific
2. **Mamba Architecture**: State-of-the-art selective SSM with input-dependent parameters
3. **Two Design Options**: Test both superposition (Option A) and hybrid (Option B) approaches

---

## ğŸ“Š The Two Quantum Mamba Models

### **Option A: Quantum Mamba (Superposition)** ğŸ”µ

**File:** `QuantumMamba.py`

**Mathematical Formulation:**
```
|ÏˆâŸ© = Î±|Ïˆ_ssmâŸ© + Î²|Ïˆ_gateâŸ© + Î³|Ïˆ_skipâŸ©
where Î±, Î², Î³ âˆˆ â„‚ (complex coefficients)

|Ïˆ_ssmâŸ©  = Q_SelectiveSSM|XâŸ©    (state-space path)
|Ïˆ_gateâŸ© = Q_Gating|XâŸ©          (gating path)
|Ïˆ_skipâŸ© = Q_Skip|XâŸ©            (skip connection)
```

**Key Features:**
- **Quantum superposition** of three pathways before measurement
- **Complex-valued trainable coefficients** (Î±, Î², Î³)
- **Single measurement** on combined quantum state
- **Potential for quantum interference** between SSM, gating, and skip paths
- **Fewer quantum circuit calls** per forward pass

**Advantages:**
- âœ“ Quantum interference may capture non-classical correlations
- âœ“ True quantum superposition (not just classical mixing)
- âœ“ Exponential state space (2^n)
- âœ“ Fewer measurements required

**Limitations:**
- âœ— Different semantics from classical Mamba
- âœ— Sensitive to quantum decoherence
- âœ— Complex coefficient optimization
- âœ— Harder to interpret

**Code Structure:**
```python
class QuantumMambaLayer(nn.Module):
    def __init__(self, n_qubits, qlcu_layers, ...):
        # Complex coefficients for superposition
        self.alpha_real = nn.Parameter(torch.rand(1))
        self.alpha_imag = nn.Parameter(torch.zeros(1))
        self.beta_real = nn.Parameter(torch.rand(1))
        self.beta_imag = nn.Parameter(torch.zeros(1))
        self.gamma_real = nn.Parameter(torch.rand(1))
        self.gamma_imag = nn.Parameter(torch.zeros(1))

        # Three quantum paths
        self.ssm_path = QuantumSelectiveSSM(...)
        self.gate_path = QuantumGatingPath(...)
        self.skip_path = QuantumSkipPath(...)

    def forward(self, x):
        # Compute three quantum states
        psi1 = self.ssm_path(x)   # SSM
        psi2 = self.gate_path(x)  # Gating
        psi3 = self.skip_path(x)  # Skip

        # QUANTUM SUPERPOSITION
        alpha = torch.complex(self.alpha_real, self.alpha_imag)
        beta = torch.complex(self.beta_real, self.beta_imag)
        gamma = torch.complex(self.gamma_real, self.gamma_imag)

        psi_combined = alpha * psi1 + beta * psi2 + gamma * psi3
        psi_normalized = psi_combined / norm(psi_combined)

        # Measure
        return output_layer(abs(psi_normalized))
```

---

### **Option B: Quantum Mamba (Hybrid)** ğŸŸ¢

**File:** `QuantumMambaHybrid.py`

**Mathematical Formulation:**
```
yâ‚ = Measure(Q_SelectiveSSM|XâŸ©)
yâ‚‚ = Measure(Q_Gating|XâŸ©)
yâ‚ƒ = Measure(Q_Skip|XâŸ©)

Y = OutputLayer(wâ‚Â·yâ‚ + wâ‚‚Â·yâ‚‚ + wâ‚ƒÂ·yâ‚ƒ)
where wâ‚, wâ‚‚, wâ‚ƒ âˆˆ â„ (real weights)
```

**Key Features:**
- **Three independent quantum circuits**
- **Classical weighted combination** of measurements
- **Real-valued trainable weights**
- **Faithful to classical Mamba's addition semantics**
- **More interpretable** branch contributions

**Advantages:**
- âœ“ Preserves classical Mamba semantics
- âœ“ Interpretable (can analyze each branch)
- âœ“ More robust to quantum noise
- âœ“ Real-valued weights (easier optimization)
- âœ“ Branch contribution analysis available

**Limitations:**
- âœ— No quantum interference
- âœ— More quantum circuit calls (three separate circuits)
- âœ— Higher computational cost

**Code Structure:**
```python
class QuantumMambaHybridLayer(nn.Module):
    def __init__(self, n_qubits, qlcu_layers, ...):
        # Real-valued weights
        self.w1 = nn.Parameter(torch.ones(1))  # SSM weight
        self.w2 = nn.Parameter(torch.ones(1))  # Gate weight
        self.w3 = nn.Parameter(torch.ones(1))  # Skip weight

        # Branch-specific processing
        self.branch1_ff = nn.Linear(...)  # SSM path
        self.branch2_ff = nn.Linear(...)  # Gate path
        self.branch3_ff = nn.Linear(...)  # Skip path

    def forward(self, x):
        # Measure each branch independently
        y1 = measure(self.branch1_qnode(x))  # SSM
        y2 = measure(self.branch2_qnode(x))  # Gate
        y3 = measure(self.branch3_qnode(x))  # Skip

        # CLASSICAL WEIGHTED COMBINATION
        w_sum = abs(w1) + abs(w2) + abs(w3)
        y_combined = (w1/w_sum)*y1 + (w2/w_sum)*y2 + (w3/w_sum)*y3

        return output_layer(y_combined)
```

---

## ğŸ”¬ Quantum Circuit Components

### 1. Quantum Selective SSM Circuit

Implements the selective state-space model with **input-dependent B, C, dt parameters**.

```python
def selective_ssm_circuit(qlcu_params, b_params, c_params, dt_params):
    """
    Quantum implementation of selective SSM.

    Classical Mamba SSM:
        h[t] = A * h[t-1] + B(u) * u[t]
        y[t] = C(u) * h[t] + D * u[t]

    Quantum implementation:
        - QLCU: Simulates A matrix (state evolution)
        - b_params: Input-dependent B matrix
        - c_params: Input-dependent C matrix
        - dt_params: Time-step parameters
    """
    # A matrix transformation (via QLCU)
    for layer in range(qlcu_layers):
        qml.RY(qlcu_params)
        qml.IsingXX(qlcu_params)

        # Input-dependent B matrix
        qml.RY(b_params)

        qml.RY(qlcu_params)
        qml.IsingYY(qlcu_params)

        # Output-dependent C matrix
        qml.RZ(c_params)

        # Time-step modulation
        qml.RX(dt_params)
```

**Key features:**
- âœ“ Input-dependent parameters (B, C, dt)
- âœ“ QLCU for state transformation
- âœ“ Time-step modulation
- âœ“ Entanglement for state mixing

---

### 2. Quantum Gating Circuit

Implements the multiplicative gating mechanism (like SiLU gating in Mamba).

```python
def gating_circuit(gate_params):
    """
    Quantum gating mechanism.

    Classical Mamba:
        output = y * silu(z)

    Quantum implementation:
        Controlled gates for multiplicative gating
    """
    for layer in range(gate_layers):
        qml.RX(gate_params)
        qml.CRZ(gate_params)  # Gating via controlled rotations
        qml.RY(gate_params)
        qml.CRZ(gate_params)
```

**Key features:**
- âœ“ Controlled gates for gating
- âœ“ Ring connectivity
- âœ“ Mimics SiLU gating behavior

---

### 3. Quantum Skip Circuit

Implements skip connection (D matrix in Mamba).

```python
def skip_circuit(skip_params):
    """
    Quantum skip connection.

    Classical Mamba:
        y[t] += D * u[t]

    Quantum implementation:
        Diagonal operations for direct path
    """
    qml.RX(skip_params)
    qml.RY(skip_params)
    qml.RZ(skip_params)
```

**Key features:**
- âœ“ Diagonal operations
- âœ“ Independent on each qubit
- âœ“ Direct input-to-output path

---

## ğŸ“ˆ Model Architectures

### QuantumMambaLayer (Option A)

```
Input (batch, feature_dim)
    â†“
Feature Projection â†’ (batch, n_params)
    â†“
Three Quantum Paths:
    â”œâ”€ QuantumSelectiveSSM â†’ |Ïˆ_ssmâŸ©
    â”œâ”€ QuantumGatingPath   â†’ |Ïˆ_gateâŸ©
    â””â”€ QuantumSkipPath     â†’ |Ïˆ_skipâŸ©
    â†“
QUANTUM SUPERPOSITION
    |ÏˆâŸ© = Î±|Ïˆ_ssmâŸ© + Î²|Ïˆ_gateâŸ© + Î³|Ïˆ_skipâŸ©
    â†“
Normalization
    â†“
Measurement (|Ïˆ|)
    â†“
Output Layer â†’ (batch, output_dim)
```

### QuantumMambaHybridLayer (Option B)

```
Input (batch, feature_dim)
    â†“
Feature Projection â†’ (batch, n_params)
    â†“
Three Independent Quantum Circuits:
    â”œâ”€ Branch 1 QNode â†’ Measure â†’ yâ‚
    â”œâ”€ Branch 2 QNode â†’ Measure â†’ yâ‚‚
    â””â”€ Branch 3 QNode â†’ Measure â†’ yâ‚ƒ
    â†“
CLASSICAL WEIGHTED COMBINATION
    y = wâ‚Â·yâ‚ + wâ‚‚Â·yâ‚‚ + wâ‚ƒÂ·yâ‚ƒ
    â†“
Output Layer â†’ (batch, output_dim)
```

### QuantumMambaTS (Time-Series)

```
Input (batch, channels, timesteps)
    â†“
Temporal Conv1d (like Mamba)
    â†“
Adaptive Pooling
    â†“
Feature Projection
    â†“
QuantumMamba Layer (Option A or B)
    â†“
Output Layer â†’ (batch, output_dim)
```

---

## ğŸš€ Usage

### Quick Start

```python
import torch
from QuantumMamba import QuantumMambaLayer, QuantumMambaTS
from QuantumMambaHybrid import QuantumMambaHybridLayer, QuantumMambaHybridTS

# Option A: Superposition
model_a = QuantumMambaTS(
    n_qubits=6,
    n_timesteps=200,
    qlcu_layers=2,
    gate_layers=2,
    feature_dim=129,
    output_dim=2,
    device="cuda"
)

# Option B: Hybrid
model_b = QuantumMambaHybridTS(
    n_qubits=6,
    n_timesteps=200,
    qlcu_layers=2,
    gate_layers=2,
    feature_dim=129,
    output_dim=2,
    device="cuda"
)

# Forward pass
x = torch.randn(16, 129, 200)  # (batch, channels, timesteps)
output_a = model_a(x)  # (batch, 2)
output_b = model_b(x)  # (batch, 2)
```

### Branch Contribution Analysis (Option B only)

```python
# Analyze which branch contributes most
contributions = model_b.quantum_mamba.get_branch_contributions(x[:4])

print(f"SSM branch shape: {contributions['branch1_ssm'].shape}")
print(f"Gate branch shape: {contributions['branch2_gate'].shape}")
print(f"Skip branch shape: {contributions['branch3_skip'].shape}")
print(f"Weights: SSM={contributions['weights']['w1_ssm']:.3f}, "
      f"Gate={contributions['weights']['w2_gate']:.3f}, "
      f"Skip={contributions['weights']['w3_skip']:.3f}")
```

### Training Example

```python
import torch.nn as nn
import torch.optim as optim

# Setup
model = QuantumMambaTS(n_qubits=6, output_dim=2)
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=1e-3)

# Training loop
for epoch in range(num_epochs):
    for x_batch, y_batch in train_loader:
        optimizer.zero_grad()
        outputs = model(x_batch)
        loss = criterion(outputs, y_batch)
        loss.backward()
        optimizer.step()
```

---

## ğŸ” Comparison with Quantum Hydra

| Aspect | Quantum Hydra | Quantum Mamba |
|--------|---------------|---------------|
| **Base Architecture** | Bidirectional Hydra (shift/flip) | Selective SSM (input-dependent) |
| **Key Mechanism** | Shift, Flip, Diagonal | Selective B/C/dt, Gating, Skip |
| **Classical Paper** | Hwang et al. 2024 | Gu & Dao 2024 |
| **Branch 1** | Qshift(QLCU\|XâŸ©) | Q_SelectiveSSM\|XâŸ© |
| **Branch 2** | Qflip(Qshift(QLCU(Qflip\|XâŸ©))) | Q_Gating\|XâŸ© |
| **Branch 3** | QD\|XâŸ© | Q_Skip\|XâŸ© |
| **Superposition** | Î±\|Ïˆâ‚âŸ© + Î²\|Ïˆâ‚‚âŸ© + Î³\|Ïˆâ‚ƒâŸ© | Î±\|Ïˆ_ssmâŸ© + Î²\|Ïˆ_gateâŸ© + Î³\|Ïˆ_skipâŸ© |
| **Hybrid** | wâ‚Â·yâ‚ + wâ‚‚Â·yâ‚‚ + wâ‚ƒÂ·yâ‚ƒ | wâ‚Â·yâ‚ + wâ‚‚Â·yâ‚‚ + wâ‚ƒÂ·yâ‚ƒ |

---

## ğŸ§ª Ablation Study Design

### Research Questions

1. **Architecture-Specific vs General Quantum Advantage**
   - Does quantum superposition help more in Hydra or Mamba?
   - Are quantum advantages specific to certain SSM architectures?

2. **Superposition vs Hybrid**
   - Option A vs Option B for both Hydra and Mamba
   - Which design benefits more from quantum interference?

3. **Comparison Matrix**

| Model | Type | Quantum | Classical |
|-------|------|---------|-----------|
| Quantum Hydra (Super) | Option A | âœ“ | - |
| Quantum Hydra (Hybrid) | Option B | âœ“ | - |
| Quantum Mamba (Super) | Option A | âœ“ | - |
| Quantum Mamba (Hybrid) | Option B | âœ“ | - |
| True Classical Hydra | Baseline | - | âœ“ |
| True Classical Mamba | Baseline | - | âœ“ |

**Total: 6 models**

### Metrics to Track

- **Accuracy**: Classification performance
- **AUC**: Area under ROC curve
- **F1 Score**: Balanced metric
- **Training Time**: Computational cost
- **Parameters**: Model size
- **Branch Contributions**: Which path is most important (Option B only)

---

## ğŸ“Š Expected Results

### Hypotheses

**H1: Quantum advantages are general**
- Both Quantum Hydra and Quantum Mamba outperform classical baselines
- Quantum superposition helps regardless of architecture

**H2: Quantum advantages are architecture-specific**
- Only one of Quantum Hydra/Mamba shows improvements
- Some architectures benefit more from quantum circuits

**H3: Superposition matters**
- Option A (superposition) outperforms Option B (hybrid)
- Quantum interference is crucial for advantages

**H4: Hybrid is more practical**
- Option B (hybrid) more robust to noise
- Easier to train and interpret

---

## ğŸ› ï¸ Implementation Details

### Parameter Counts

**Option A (Superposition):**
- QLCU params: 4 Ã— n_qubits Ã— qlcu_layers
- Gate params: (3 Ã— n_qubits + n_qubits) Ã— gate_layers
- Skip params: 3 Ã— n_qubits
- Selective params: 3 Ã— n_qubits (B, C, dt)
- Complex coefficients: 6 (real + imag for Î±, Î², Î³)

**Option B (Hybrid):**
- Branch 1 params: 4 Ã— n_qubits Ã— qlcu_layers + 3 Ã— n_qubits
- Branch 2 params: (3 Ã— n_qubits + n_qubits) Ã— gate_layers
- Branch 3 params: 3 Ã— n_qubits
- Classical weights: 3 (wâ‚, wâ‚‚, wâ‚ƒ)

### Quantum Backend

- **Framework**: PennyLane
- **Device**: `default.qubit` (noiseless simulation)
- **Differentiation**: `backprop` (auto-diff through quantum circuits)
- **Interface**: `torch` (PyTorch integration)

### Typical Configuration

```python
n_qubits = 6          # 2^6 = 64 dimensional quantum state
qlcu_layers = 2       # Circuit depth for SSM
gate_layers = 2       # Circuit depth for gating
feature_dim = 129     # EEG channels
n_timesteps = 200     # EEG timesteps
output_dim = 2        # Binary classification
batch_size = 16
learning_rate = 1e-3
```

---

## ğŸ“ Key Differences from Classical Mamba

### Classical Mamba (Gu & Dao, 2024)

```python
# Selective SSM
B = Linear(input)     # Input-dependent
C = Linear(input)     # Input-dependent
dt = Softplus(Linear(input))

# State evolution
h[t] = A * h[t-1] + B * u[t]
y[t] = C * h[t] + D * u[t]

# Gating
output = y * silu(gate)
```

### Quantum Mamba (This Implementation)

```python
# Quantum selective SSM
b_params = f(input)   # Input-dependent quantum params
c_params = f(input)
dt_params = f(input)

# Quantum state evolution (via QLCU)
|Ïˆ[t]âŸ© = QLCU(b, c, dt) |Ïˆ[t-1]âŸ©

# Three quantum paths
|Ïˆ_ssmâŸ© = Q_SelectiveSSM(b, c, dt) |XâŸ©
|Ïˆ_gateâŸ© = Q_Gating |XâŸ©
|Ïˆ_skipâŸ© = Q_Skip |XâŸ©

# Superposition (Option A) or Classical (Option B)
|ÏˆâŸ© = Î±|Ïˆ_ssmâŸ© + Î²|Ïˆ_gateâŸ© + Î³|Ïˆ_skipâŸ©  (A)
y = wâ‚Â·yâ‚ + wâ‚‚Â·yâ‚‚ + wâ‚ƒÂ·yâ‚ƒ                (B)
```

---

## âœ… Testing

Both models include comprehensive test suites:

```bash
# Test Option A (Superposition)
python QuantumMamba.py

# Test Option B (Hybrid)
python QuantumMambaHybrid.py
```

**Expected output:**
- âœ“ Model initialization
- âœ“ Forward pass (correct shapes)
- âœ“ Gradient flow verification
- âœ“ Parameter count
- âœ“ Branch contribution analysis (Option B)

---

## ğŸ”— Related Files

- `QuantumMamba.py` - Option A implementation
- `QuantumMambaHybrid.py` - Option B implementation
- `TrueClassicalMamba.py` - Classical baseline for comparison
- `QuantumHydra.py` - Quantum Hydra (Option A)
- `QuantumHydraHybrid.py` - Quantum Hydra (Option B)
- `TrueClassicalHydra.py` - Classical Hydra baseline
- `QUANTUM_HYDRA_README.md` - Quantum Hydra documentation
- `COMPARISON_README.md` - Model comparison documentation

---

## ğŸ“š References

### Papers

1. **Gu & Dao (2024)** - "Mamba: Linear-Time Sequence Modeling with Selective State Spaces"
   - https://arxiv.org/html/2312.00752v2
   - Original Mamba architecture

2. **Hwang et al. (2024)** - "Hydra: Bidirectional State Space Models Through Generalized Matrix Mixers"
   - https://arxiv.org/pdf/2407.09941
   - Hydra architecture for comparison

### Code

- Mamba GitHub: https://github.com/state-spaces/mamba
- PennyLane: https://pennylane.ai/

---

## ğŸ’¡ Design Philosophy

### Why Three Branches?

Both Quantum Hydra and Quantum Mamba use three branches following their classical counterparts:

**Classical Hydra:**
```
QS(X) = shift(SS(X)) + flip(shift(SS(flip(X)))) + DX
        â””â”€ Branch 1â”€â”˜   â””â”€â”€â”€â”€â”€â”€ Branch 2 â”€â”€â”€â”€â”€â”€â”˜   â””â”€3â”€â”˜
```

**Classical Mamba:**
```
output = SSM(u) + Gate(u) + Skip(u)
         â””â”€ 1 â”€â”˜   â””â”€ 2 â”€â”˜   â””â”€ 3 â”€â”˜
```

**Quantum versions maintain this structure** to enable fair comparison with classical baselines.

### Why Two Options (A & B)?

- **Option A (Superposition)**: Tests if quantum interference helps
- **Option B (Hybrid)**: More faithful to classical semantics, easier to interpret

By implementing both, we can determine:
1. If quantum advantages exist
2. If they come from interference (A) or quantum circuits alone (B)

---

## ğŸ¯ Next Steps

1. **Run ablation study** with all 6 models
2. **Compare performance** on EEG/fMRI datasets
3. **Analyze branch contributions** (Option B)
4. **Test noise robustness**
5. **Scale to larger qubit counts**

---

**Author:** Junghoon Park
**Created:** October 2024
**Status:** Production-ready
**Purpose:** Ablation study for quantum vs classical SSMs
